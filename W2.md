## Data

Reunión previa [[01_weekly_meeting]]

Recieved the images from Morlana:
https://drive.google.com/file/d/1BQAkhIbrWSbwJfkk2R__EkDxbgUflYqq/view?usp=sharing

Waiting for specular masks
### Dataset Characteristics

- En easy hay 1 submapa, el objetivo es emparejar las imágenes entre sí.

- En medium hay 3 submapas de la misma secuencia, el objetivo es emparejar submapas de un submapa contra imágenes de otros submapas.

- En hard hay 1 submapa de otra secuencia, el objetivo es emparejar submapas de medium contra él (misma idea que el trabajo de Computer Vision)

- Fish-eye Distortion.
- Image Resolution: 1350 x 1012 (w x h)
### Available Models of image-matching

from init.py (inside matching)
```python
available_models = [
"loftr", "eloftr", "se2loftr", "aspanformer", "matchformer", "sift-lg", "superpoint-lg", "disk-lg", "aliked-lg", "doghardnet-lg", "roma", "tiny-roma", "dedode", "steerers", "affine-steerers", "dedode-kornia", "sift-nn", "orb-nn", "patch2pix", "superglue", "r2d2", "d2net", "duster", "master", "doghardnet-nn", "xfeat", "xfeat-star", "xfeat-lg", "xfeat-steerers-perm", "xfeat-steerers-learned", "xfeat-star-steerers-perm", "xfeat-star-steerers-learned", "dedode-lg", "gim-dkm", "gim-lg", "omniglue", "xfeat-subpx", "xfeat-lg-subpx", "dedode-subpx", "splg-subpx", "aliked-subpx", "sift-sphereglue", "superpoint-sphereglue"
]
```

## ToDo
- Try repo with cases.
- Try repo with other models
- Automate the matching

- Should I undistort Fish eye distortion?
- Should I male a downscaleing of the Image resolution?
	Generally the detectors or matchers ave an internal preprocessing of the image.
## Doing

WARNING: MPS is not tested

Trying with own dataset

### Doubts
- Is assuming a planar image? because is calculating H. Could I calculate E? 
## Ideas
- Apply possible rotations (as in a paper that I dont remember rightnow) and try to keep one case or a mix of them
- Tip
	You can pass a list of matchers, i.e. `get_matcher([xfeat, tiny-roma])` to run both matchers and concatenate their keypoints. source:https://github.com/alexstoken/image-matching-models
- Note
	This repo is optimized for usability, not necessarily for speed or performance. Ideally you can use this repo to find the matcher that best suits your needs, and then use the original code (or a modified version of this code) to get maximize performance. Default hyperparameters used here **may not be optimal for your use case!** source:https://github.com/alexstoken/image-matching-models

 - Train with GIM? https://github.com/xuelunshen/gim?tab=readme-ov-file
-  After processing the video, it's time to train the network. The training code for `gim-loftr` is in the `train-gim-loftr` branch of the repository. The training code for `gim-dkm` and `gim-lightglue` will be released later. However, adapting the video data by `gim` to the architecture of `dkm` and `lightglue` is actually simpler than adapting it to `loftr`. Therefore, we first release the training code for `gim-loftr`.

1. Use the command `git checkout train-gim-loftr` to switch to the `train-gim-loftr` branch
2. Use the command below to run the training code

 - DKM matcher? (2. Download `gim_dkm` model weight from [Google Drive](https://drive.google.com/file/d/1gk97V4IROnR1Nprq10W9NCFUv2mxXR_-/view?usp=sharing) or [OneDrive](https://stuxmueducn-my.sharepoint.com/:u:/g/personal/xuelun_stu_xmu_edu_cn/EdJOibZ8VABOoKoyOHWo8ZEBHd_MyHbSvhRyT_o40SIPGA?e=GCjGZE)) https://github.com/xuelunshen/gim?tab=readme-ov-file
- Preprocessign with Kornia: https://github.com/kornia/kornia

## Step by Step guide to install repo

Prerequisites: 
- install python3
- install conda
Steps:
```bash
conda create --name colon_matching python=3.10

conda activate colon_matching

git clone --recursive https://github.com/alexstoken/image-matching-models

cd image-matching-models

pip install .

pip install .[all] 
OR (OH-MyZSH)
pip install '.[all]'

conda install ipykernel

conda install pandas
```

### Otros
Pedir acceso al edificio los findes en https://eina.unizar.es/solicitud-de-acceso-edificios-de-la-eina

