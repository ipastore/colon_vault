## 03-03-25
Installed COLMAP on UBUNTU

Revisando: 

En este enlace se ve las posibles secuencias que se podrían utilizar que tienen COLMAP 3D reconstructions: [Dataset Summary](https://docs.google.com/spreadsheets/d/1b9FULhh13dPhbqCXLcFTbAlwhKRGFReW/edit?usp=drive_link&ouid=104532659855887590320&rtpof=true&sd=true)

En este caso son las [Seq_001](https://drive.google.com/drive/folders/15gNjjvChngzfs97YOb17_lk_jubLrB3j?usp=drive_link) y las [Seq_002](https://drive.google.com/drive/u/4/folders/15hjA1wC2XqB1SMrFGkN1mnwpNxaIpl3k) (de la [[W4_weekly_meeting]])

## 04-03-24

Ayer traté de cargar un project.ini desde COLMAP con Macos y me decía que había unos parámetros del project.ini que quizás estaban en una versión mas nueva o mas vieja. Además que tenía que cargar un projeycto nuevo antes de importar uno, lo cual es mentira porque yo cargué el mio sin problemas. 

- Does every project.in has it´s own database and image path? Or is it just that tehre is a unique database for all the submaps? Check the paths of the project.ini.
	- There is only one database.db and only a image_path that I should change it to adapt to my machine. 
- Ask Morlana the version of COLMAP and to give me the database.db:
	  - Version 3.6,
	  - https://github.com/colmap/colmap/commits/a6ad9641a5fb06ae8315f9be7be270f79745cbcb
	  - Me da un pequeño error al parsear algun parametro del project.ini pero no debería haber mayores problemas.
-  Puedo abrir modelo por modelo y luego exportar los txt:
	- Puedo automatizarlo de otra maner? PyColmap
	- Te dan las transformaciones respecto al World, como puedo sacar la relativa entre 2 imagenes? Restando la una a la otra (implementado en PyColmap)
	
FAQ de COLMAP: https://colmap.github.io/faq.html

Extending COLMAP[](https://colmap.github.io/faq.html#extending-colmap "Link to this heading")

If you need to simply analyze the produced sparse or dense reconstructions from COLMAP, you can load the sparse models in Python and Matlab using the provided scripts in `scripts/python` and `scripts/matlab`.

Mask image regions[](https://colmap.github.io/faq.html#mask-image-regions "Link to this heading")

COLMAP supports masking of keypoints during feature extraction two different ways:

1. Passing `mask_path` to a folder with image masks. For a given image, the corresponding mask must have the same sub-path below this root as the image has below `image_path`. The filename must be equal, aside from the added extension `.png`. For example, for an image `image_path/abc/012.jpg`, the mask would be `mask_path/abc/012.jpg.png`.

2. Passing `camera_mask_path` to a single mask image. This single mask is applied to all images.
    

In both cases no features will be extracted in regions, where the mask image is black (pixel intensity value 0 in grayscale).

Downloading PYCOLMAP: https://colmap.github.io/pycolmap/index.html#pycolmap-index
I am installing in MACOS witout CUDASUPPORT. with
pip install pycolmap
IF i need in UBuntu I could install from source with CUDASUPPORT
PyCOLMAP API: https://colmap.github.io/pycolmap/index.html#api

COLMAP debería estar con máscara?

Implementé una función para plotear los keypoints. 

Refinando error_measurement.py para por lo menos medir el error de un solo par. 
```python

def undistort_images(intrinsics, rgb, mask):
camera_type = intrinsics[0]
width = int(intrinsics[1])
height = int(intrinsics[2])
fx = intrinsics[3]
fy = intrinsics[4]
cx = intrinsics[5]
cy = intrinsics[6]
distortion = np.array(intrinsics[7:])

  
K = np.zeros([3, 3])
K[0, 0] = fx
K[0, 2] = cx
K[1, 1] = fy
K[1, 2] = cy
K[2, 2] = 1

K = geometry.colmap_to_opencv_intrinsics(K)

if camera_type == "OPENCV_FISHEYE":

assert len(distortion) == 4

new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(K,
distortion,
(width, height),
np.eye(3),
balance=0.0,
)

# Make the cx and cy to be the center of the image
new_K[0, 2] = width / 2.0
new_K[1, 2] = height / 2.0

map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, distortion, np.eye(3), new_K, (width, height), cv2.CV_32FC1)

else:

new_K, _ = cv2.getOptimalNewCameraMatrix(K, distortion, (width, height), 1, (width, height), True)

map1, map2 = cv2.initUndistortRectifyMap(K, distortion, np.eye(3), new_K, (width, height), cv2.CV_32FC1)

undistorted_image = cv2.remap(rgb, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)

undistorted_mask = cv2.remap(mask, map1, map2, interpolation=cv2.INTER_LINEAR,

borderMode=cv2.BORDER_CONSTANT, borderValue=255)

K = geometry.opencv_to_colmap_intrinsics(K)

return width, height, new_K, undistorted_image, undistorted_mask

def colmap_to_opencv_intrinsics(K):

"""
Modify camera intrinsics to follow a different convention.
Coordinates of the center of the top-left pixels are by default:
- (0.5, 0.5) in Colmap
- (0,0) in OpenCV

"""

K = K.copy()
K[0, 2] -= 0.5
K[1, 2] -= 0.5

return K

def opencv_to_colmap_intrinsics(K):

"""
Modify camera intrinsics to follow a different convention.
Coordinates of the center of the top-left pixels are by default:
- (0.5, 0.5) in Colmap
- (0,0) in OpenCV
"""
K = K.copy()
K[0, 2] += 0.5
K[1, 2] += 0.5

return K
```


## 05-03-25

TAKE INTO ACCOUNT: Now I am missing the inlier filter when plotting all in green. I am going to introduce some error in the relative pose calculation because of outliers.

I will use COLMAP API to compare with the COLMAP MODEL.

[[pycolmap_estimate_essential_matrix |How to use estiamate_essential_matrix of pycolmap]]

Decsissions:

Covert matches to COLMAP matches (0.5)
Use the built-in function of estiamte_essential_matrix to calculate the E from my custom matches.
Don´t filter the matches previously to calculate the E because COLMAP handles it within the built-in function
Compute the relative pose of the COLMAP pseudo-ground truth using 

```python
def compute_relative_pose(cam_from_world1, cam_from_world2):
    """
    Compute relative pose (R, t) between two camera absolute poses.
    Args:
        cam_from_world1 (pycolmap.Rigid3d): Absolute pose of camera 1 (world -> cam1).
        cam_from_world2 (pycolmap.Rigid3d): Absolute pose of camera 2 (world -> cam2).
    Returns:
        R_rel (numpy.ndarray): 3x3 relative rotation matrix.
        t_rel (numpy.ndarray): 3x1 relative translation vector.
    """
    cam2_from_cam1 = cam_from_world1.inverse() * cam_from_world2 
    
    return cam2_from_cam1.rotation.matrix(), cam2_from_cam1.translation

```

[[how_to_compute_error_sketch |Error measurement: first sketch idea of mAA pipeline]]

[[scale_of_tvec_in_error_measurement|About scale of tvec in error measurement pipline]]

Just commit the first pipeline to measure the mAA with one pair and one model

