
## Anotaciones Generales

Available new models:  minima-roma,xoftr, minima-loftr. minima-splg

**Dense**: `roma, tiny-roma, dust3r, mast3r, minima-roma`

**Semi-dense**: `loftr, eloftr, se2loftr, xoftr, minima-loftr, aspanformer, matchformer, xfeat-star, xfeat-star-steerers[-perm/-learned],`

**Sparse**: `[sift, superpoint, disk, aliked, dedode, doghardnet, gim, xfeat]-lg, dedode, steerers, affine-steerers, xfeat-steerers[-perm/learned], dedode-kornia, [sift, orb, doghardnet]-nn, patch2pix, superglue, r2d2, d2net, gim-dkm, xfeat, omniglue, [dedode, xfeat, aliked]-subpx, [sift, superpoint]-sphereglue, minima-splg`


## 17-02-25
### Reunión grupal: 
Mejorar máscaras, instalar any desk. 
Cuidado con la matriz F, E y H porque asumen un modelo rígido. Seguir discusión.
Las fotos de los medium y hard cases son visibles por el ojo de Morlana. No es lo mismo CREO el covisibility graph de que sean covisibles. 

## 18-02-25
Cambios en el main repo:

Aplicar cambios de image-matching-models repo. 
Probar MINIMA
Probar los cambios de Roma

TODO: 
aplicar bien las mascaras
##
## 19-0 2-25
Instalé AnyDesk
Reclono repo git en ubuntu
faltó en hard mode: gim-lg y sift-nn: lo corrí en Ubuntu
Pruebo modelos pesados en GPU ubuntu
subo outputs a Drive

No anduvo el anydesk
hay un tema cuando instalo la librería matching, el path es el del env de conda no mi directorio local actualizado. La solución es instalar con la flag -e: pip install -e .
Así anda salbo el minima-splg que da un error como 
```bash
Traceback (most recent call last):

File "/Users/ignaciopastorebenaim/Documents/MGRCV/COLON/colon_matching/run_models.py", line 46, in <module>
    matcher = get_matcher(model_name, device=device)
  File "/Users/ignaciopastorebenaim/anaconda3/envs/colon_matchingV2/lib/python3.10/site-packages/matching/utils.py", line 158, in wrapper
    return func(*a, **ka)
  File "/Users/ignaciopastorebenaim/anaconda3/envs/colon_matchingV2/lib/python3.10/site-packages/matching/__init__.py", line 305, in get_matcher
    from matching.im_models import minima
  File "/Users/ignaciopastorebenaim/anaconda3/envs/colon_matchingV2/lib/python3.10/site-packages/matching/im_models/minima.py", line 14, in <module>
    from src.utils.load_model import load_model, load_sp_lg, load_loftr, load_roma
ModuleNotFoundError: No module named 'src'
```

Conclusion no es el environment instalado con la flag -e

## 20-02-25

Revisar anydesk: **no apagar monitor**
reinstalar el environment de ubuntu con -e: **hecho**
investigar el problema con minima-splg: **es que no había reinicializado los submodules**

```bash
# Initialize and update all submodules recursively
git submodule update --init --recursive
```

correr el ROMA: hecho

[[W4_weekly_meeting]]

Arreglar quilombo del ultimo commit ignore .pth wheights de image-matching (en Ubuntu no se por qué no lo tracke, quizás porque empecé a trackera la carpeta gim):
Conclusión: al instalar con -e agarra el path local por un symlink. No utiliza el envs. Entoncees te queda el archivo untracked. Para solucionarlo habría que modificar el gitignore del submodule de git pero eso significan 3 pushes (por cada modulo) y lo mismo con los pulls por cada modulo del otro lado, no vale la pena. **Simplemente trabajar con ese untracked file colgado por ahi**

## 21-02-25

run.models.py
50 process_image_pairs ()
process_image_pairs.py
24 matcher(img0,img1)
base_matcher.py. 

Dentro de Class BaseMatcher,
Define parametros de RAnsac

dentro def forward(), toma dos imagenes y devuelve estructura de return
179: self_forward(img0, img1)
182: self.precess_matches(matched_kpts0, matched_kpts1) FIltra con LA H REVISAR

183: se mete a self._forward que es el método propio de cada uno

Para gim-lg o gim-tiny-roma no tengo que modificar nada mas

# Para ROMA
To integrate the mask functionality into the `tiny_roma_v1_model` and ensure it propagates through the entire pipeline, you need to make modifications in several places. Here are the steps and the specific functions you should modify:

1. **Modify the `TinyRoMa` class** to accept and process the mask.
2. **Update the `tiny_roma_v1_model` function** to pass the mask.
3. **Modify the `process_image_pairs` function** to accept a mask.
4. **Ensure the `matcher` function in `process_image_pairs` accepts a mask**.
5. **Update the `BaseMatcher` class** to accept a mask in the `_forward` method.
6. **Modify the `roma_model` function** to create a model with a mask.

### Step 1: Modify the `TinyRoMa` Class

Modify the `TinyRoMa` class to accept and process the mask:

```python
class TinyRoMa(nn.Module):
    def __init__(self, xfeat=None, freeze_xfeat=False, exact_softmax=False):
        super(TinyRoMa, self).__init__()
        # ...existing code...
        self.mask_token = nn.Parameter(torch.zeros(1, 1, 1))  # Add mask token

    def forward(self, img0, img1, mask0=None, mask1=None):
        # ...existing code...
        if mask0 is not None:
            img0 = torch.where(mask0.unsqueeze(1), self.mask_token.to(img0.dtype), img0)
        if mask1 is not None:
            img1 = torch.where(mask1.unsqueeze(1), self.mask_token.to(img1.dtype), img1)
        # ...existing code...
        return output
```

### Step 2: Update the `tiny_roma_v1_model` Function

Update the `tiny_roma_v1_model` function to pass the mask:

```python
def tiny_roma_v1_model(weights=None, freeze_xfeat=False, exact_softmax=False, xfeat=None):
    model = TinyRoMa(
        xfeat=xfeat,
        freeze_xfeat=freeze_xfeat,
        exact_softmax=exact_softmax
    )
    if weights is not None:
        model.load_state_dict(weights)
    return model

# Example usage
img0 = torch.randn(1, 3, 224, 224)  # Example input image
img1 = torch.randn(1, 3, 224, 224)  # Example input image
mask0 = torch.zeros(1, 224, 224)  # Example mask with the same spatial dimensions as the input image
mask1 = torch.zeros(1, 224, 224)  # Example mask with the same spatial dimensions as the input image
mask0[:, 50:100, 50:100] = 1  # Mask out a region
mask1[:, 50:100, 50:100] = 1  # Mask out a region

model = tiny_roma_v1_model()
output = model(img0, img1, mask0=mask0, mask1=mask1)
```

### Step 3: Modify the `process_image_pairs` Function

Modify the `process_image_pairs` function to accept a mask:

```python
def process_image_pairs(matcher, img0, img1, mask0=None, mask1=None):
    # ...existing code...
    result = matcher(img0, img1, mask0=mask0, mask1=mask1)
    # ...existing code...
    return result
```

### Step 4: Ensure the `matcher` Function in `process_image_pairs` Accepts a Mask

Ensure the `matcher` function in `process_image_pairs` accepts a mask:

```python
class BaseMatcher(nn.Module):
    def __init__(self, ...):
        # ...existing code...

    def _forward(self, img0, img1, mask0=None, mask1=None):
        # ...existing code...
        if mask0 is not None:
            img0 = torch.where(mask0.unsqueeze(1), self.mask_token.to(img0.dtype), img0)
        if mask1 is not None:
            img1 = torch.where(mask1.unsqueeze(1), self.mask_token.to(img1.dtype), img1)
        # ...existing code...
        return output
```

### Step 5: Update the `BaseMatcher` Class

Update the `BaseMatcher` class to accept a mask in the `_forward` method:

```python
class BaseMatcher(nn.Module):
    def __init__(self, ...):
        # ...existing code...

    def _forward(self, img0, img1, mask0=None, mask1=None):
        # ...existing code...
        if mask0 is not None:
            img0 = torch.where(mask0.unsqueeze(1), self.mask_token.to(img0.dtype), img0)
        if mask1 is not None:
            img1 = torch.where(mask1.unsqueeze(1), self.mask_token.to(img1.dtype), img1)
        # ...existing code...
        return output
```

### Step 6: Modify the `roma_model` Function

Modify the `roma_model` function to create a model with a mask:

```python
def roma_model(resolution, upsample_preds, device=None, weights=None, dinov2_weights=None, amp_dtype: torch.dtype=torch.float16, **kwargs):
    # ...existing code...
    matcher = RegressionMatcher(encoder, decoder, h=h, w=w, upsample_preds=upsample_preds, 
                                symmetric=symmetric, attenuate_cert=attenuate_cert, sample_mode=sample_mode, **kwargs).to(device)
    matcher.load_state_dict(weights)
    return matcher

# Example usage
img0 = torch.randn(1, 3, 224, 224)  # Example input image
img1 = torch.randn(1, 3, 224, 224)  # Example input image
mask0 = torch.zeros(1, 224, 224)  # Example mask with the same spatial dimensions as the input image
mask1 = torch.zeros(1, 224, 224)  # Example mask with the same spatial dimensions as the input image
mask0[:, 50:100, 50:100] = 1  # Mask out a region
mask1[:, 50:100, 50:100] = 1  # Mask out a region

model = roma_model(resolution=(224, 224), upsample_preds=True)
output = model(img0, img1, mask0=mask0, mask1=mask1)
```

By following these steps, you can ensure that the `tiny_roma_v1_model` and `roma_model` functions can accept and process masks, allowing you to exclude certain pixels from being matched.

[[Git_Cheatsheet]]

## 24-02-25

El finde estuve arreglando el repo: tengo que hacer 3 pulls and push si modifico un sub submodule

Además estuve aplicando las máscaras a todo el algoritmo, principalmente lightglue y roma. Estoy debugeando para lightglue, estuve aplicando e implementando cosas: para la interfaz, con el matcher y para el thirdpartiy (creo que para im_models también) pero acabo de ver que creo que lightglue acepta máscaras en lightglue.py linea 152 el método forward()